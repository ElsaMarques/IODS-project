---
output: 
  html_document: 
    fig_height: 3
    fig_width: 5
    highlight: espresso
---

# Logistic regression

*This chapter introduces you the concept of logistic regression. Which in a very simplified matter meand how well your data fits to the idea of a linear correlation between the variables, arguments you are testing.*

# *About this week working data set "Student Performance Data Set*

> "This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks (see [paper](http://www3.dsi.uminho.pt/pcortez/student.pdf) source for more details)."


## 1. **Load the combined data set from wrangling exercise from your local folder:**
```{r, echo = FALSE}
#Read the data you saved in the wrangling data exercises
read.csv("student-combined.csv")
alc <- read.csv("student-combined.csv")
```

The data wrangling exercise combined the two student alcohol consumption data sets. 
Variables not used for joining the two data have been combined by averaging (including the grade variables)
  - 'alc_use' is the average of 'Dalc' and 'Walc'
  - 'high_use' is TRUE if 'alc_use' is higher than 2 and FALSE otherwise


##2. **Analysis of the data** 
###2.1 *start by viewing the variable names, example of the first rows in the data, summary of the overall data*

```{r, echo = FALSE}
#Listing the column names
colnames(alc)
```

```{r, echo=FALSE}
head(alc)
```


```{r, echo=FALSE}
summary(alc)
```

 - With this overview of the data you can basically just check one by one what are the minimum and maximum values for each variable and also the total number of female and male students in the course.
 
 
###2.2 *Another why to inspect the data is to check summaries of the data by groups of variables*

```{r,echo=FALSE}
# access the tidyverse libraries dplyr and ggplot2
library(dplyr); library(ggplot2)

# produce summary statistics by group
alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade = mean(G3))
```

###2.1 *Analyse the relationship between the levels of high alcohol consuption and failure, absences, sex and grades of the students.* 

One could associate that an increased alcohol consuption will lead to an increase in failures, absences from school and also with a decrease in the final grades (grade form the 3rd period = G3). The differences of alcohol intake amongs sex and age seems also interesting to explore (once there is the stereotyped idea that males drink more and younger students are not leagally allowed to drink). 


```{r,echo=FALSE}
# find the model with glm()
m <- glm(high_use ~ age + absences + sex + G3, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# print out the coefficients of the model
coef(m)
```

failures     0.34596    0.20496   1.688  0.09142 .  
absences     0.09135    0.02293   3.983 6.81e-05 ***
sexM         0.95321    0.24278   3.926 8.63e-05 ***
G3    




##3. **Inspect numerically and graphically the distributions of the previously chosen variables and their relationship with alcohol consumption**

```{r,echo=FALSE}
# initialize a plot of high_use and G3
g1 <- ggplot(alc, aes(x = high_use, y = G3, fill = sex))

# define the plot as a boxplot and draw it
g1 + geom_boxplot() + ylab("grade") + ggtitle("Student grades by alcohol consumption and sex")

```
```{r, echo=FALSE}
library(gmodels)
CrossTable(alc$high_use, alc$age)
```

You can observe that high use of alcohol didn't alter the average final grades (G3 in the data set) of the female students, and only sligly decreases the amount of the maximum grades. As for the male students you can see a clear drop in the average grades as also the maximum grades (you can see this from the variation lines)

```{r,echo=FALSE}
# initialise a plot of high_use and absences
g2 <- ggplot(alc, aes(x = high_use, y = absences, fill = sex))

# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ggtitle("Student absences by alcohol consumption and sex")
```
```{r, echo=FALSE}
CrossTable(alc$high_use, alc$absences)
```

Once again the high use of alcohol didn't alter the average number of absences of the female students, and only sligly increased the amount of the maximum number of absences (top of the box plot). As before, the alcohol consuption has more effect on the male students. You can see that the absences number increased (noticeable from the increase in the average of absences, the mimunim number of absences and maximum number of absences). 

```{r,echo=FALSE}
# initialise a plot of high_use and age
g2 <- ggplot(alc, aes(x = high_use, y = age, fill = sex))

# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ggtitle("Student age by alcohol consumption and sex")
```

```{r, echo = FALSE}
CrossTable(alc$high_use, alc$age)
```

You can see that while the heavy alcohol consumption in the females is distributed from 16 to 17 yeard old, in the male students the high alcohol intake spreads from 16 to 18 years old. If you compare this ages with the ones from the low or non alcohol consumption, you can realize that all the male students with 17y or older are high user of alcohol.  



##4. *Use logistic regression to statistically explore the relationship between chosen variables and the binary high/low alcohol consumption variable as the target variable.*

```{r,echo=FALSE}
# find the model with glm()
m <- glm(high_use ~ age + absences + sex + G3, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# print out the coefficients of the model
coef(m)
```

###4.1 *Present and interpret the coefficients of the model as odds ratios and provide confidence intervals for them.*

```{r, echo=FALSE}
# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)
```




##5. *Compute the total proportion of inaccurately classified individuals (= the training error) and comment on all the results.*

```{r,echo=FALSE}

# predict() the probability of high_use
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, age, absences, sex, high_use, probability, prediction) %>% head(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$probability > 0.5)
```

You can check in the tables in how many student cases the prediction wouldn't have assumed a correlation for high use of alcohol and the selected variables. In the 2 x 2 summary table you can see that in 84 cases the prediction claimed no relation but in the real cases you could detect a relationship between the variables. 30 cases there was in both prediction and data analysis a relation between high use of alcohol and the chosen variables.  

##6. *Perform 10-fold cross-validation on your model*

```{r, echo=FALSE}

# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)

# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```

Performing an higher number of cross validation you can decrease the number of errors in our predictions. 

##7. *Draw a graph displaying the trends of both training and testing errors by the number of predictors in the model.*

```{r, echo=FALSE}
# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))

# define the geom as points and draw the plot
g + geom_point()

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>%
  prop.table() %>% addmargins () 
```

In this graph you can more easily evaluate how the predictions correlate with the real probability of the high use of alcohol being significantly related with the chosen variables. 















